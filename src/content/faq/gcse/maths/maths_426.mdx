---
title: "How do you use Pythagoras' Theorem to find the distance between two points?"
summary: "Pythagoras' Theorem helps calculate the distance between two points by interpreting them as coordinates on a graph."
author: "Prof. Michael Lewis"
degree: "PhD in Physics, University of Oxford"
tutor_type: "IB Physics Tutor"
date: 2024-04-05
---

You can utilize Pythagoras' Theorem to determine the distance between two points by representing them as coordinates on a graph.

To calculate the distance between two points, you first need to identify their coordinates. Let's denote these points as $ A(x_1, y_1) $ and $ B(x_2, y_2) $. When plotted on a Cartesian plane, the distance between these two points serves as the hypotenuse of a right-angled triangle, while the horizontal and vertical distances between the points represent the other two sides.

Pythagoras' Theorem asserts that in a right-angled triangle, the square of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the other two sides. This relationship can be expressed mathematically as:

$$ a^2 + b^2 = c^2 $$ 

where $ c $ represents the length of the hypotenuse.

In our scenario, the horizontal distance between points $ A $ and $ B $ is given by $ |x_2 - x_1| $, and the vertical distance is represented by $ |y_2 - y_1| $. These distances correspond to the two shorter sides of our right-angled triangle. According to Pythagoras' Theorem, the distance $ d $ between the points is calculated as follows:

$$ d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} $$

This formula enables you to compute the straight-line distance between any two points on a plane. To use this formula, simply substitute the coordinates of your points into it, carry out the necessary arithmetic operations, and you will obtain the distance. This approach is particularly beneficial in various fields, such as geometry, physics, and navigation.
    