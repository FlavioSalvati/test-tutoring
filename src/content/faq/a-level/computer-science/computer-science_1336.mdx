---
title: "What is the difference between bandwidth and latency?"
summary: "Bandwidth refers to the maximum data transfer rate of a network, while latency is the delay in data transmission over the network."
author: "Dr. Isabella Harris"
degree: "PhD in Computational Theory, University of Sheffield"
tutor_type: "A-Level Computer Science Tutor"
date: 2024-08-21
---

Bandwidth and latency are two critical concepts that define the performance of a network.

**Bandwidth** refers to the maximum data transfer rate of a network connection. It quantifies the amount of data that can be transmitted over a specific connection within a given time frame. Bandwidth is typically measured in bits per second (bps), with common multiples including Kbps (kilobits per second), Mbps (megabits per second), and Gbps (gigabits per second). A higher bandwidth allows for the transmission of more data in a shorter period. For instance, a connection with a bandwidth of $100 \, \text{Mbps}$ can theoretically transfer up to $100$ megabits of data every second. However, the actual data transfer rate may be lower due to factors such as network congestion and signal degradation.

**Latency**, on the other hand, refers to the delay experienced in the transmission of data across a network. It is generally measured in milliseconds (ms). Lower latency indicates quicker data transmission, resulting in less delay. For example, when you click on a link on a webpage, latency is the time it takes for your request to reach the server and for the server's response to come back to you. High latency can lead to noticeable delays in data transmission, which can be particularly problematic in real-time applications like online gaming or video conferencing.

Both bandwidth and latency are essential for optimal network performance, but they serve different functions. Bandwidth is concerned with the capacity of the network to transmit data, whereas latency pertains to the speed of that transmission. A network may possess high bandwidth but also experience high latency, meaning it can handle a large volume of data but with significant delays. Conversely, a network could have low bandwidth yet also exhibit low latency, allowing for the quick transmission of smaller amounts of data. Consequently, for a smooth and efficient network experience, it is beneficial to have both high bandwidth and low latency.
    