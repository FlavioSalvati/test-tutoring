---
title: "What is the binary representation of the decimal number 784?"
summary: "The binary representation of the decimal number 784 is 1100010000."
author: "Dr. Ava Johnson"
degree: "PhD in Software Development, University of Nottingham"
tutor_type: "A-Level Computer Science Tutor"
date: 2024-05-20
---

The binary representation of the decimal number $784$ is $1100010000$.

To convert a decimal number to binary, we employ a method that involves dividing the number by $2$ and tracking the remainders. We start with the number $784$ and divide it by $2$, which gives us a quotient of $392$ and a remainder of $0$. This remainder represents the least significant bit (the rightmost bit) of our binary number. We proceed by taking the quotient ($392$) and dividing it by $2$ again, yielding $196$ with a remainder of $0$. This remainder contributes the next bit of our binary representation.

We continue this process, documenting the sequence of quotients and remainders as follows:

$$
\begin{align*}
784 \div 2 &= 392 \quad \text{remainder } 0 \quad \text{(least significant bit)} \\
392 \div 2 &= 196 \quad \text{remainder } 0 \\
196 \div 2 &= 98 \quad \text{remainder } 0 \\
98 \div 2 &= 49 \quad \text{remainder } 0 \\
49 \div 2 &= 24 \quad \text{remainder } 1 \\
24 \div 2 &= 12 \quad \text{remainder } 0 \\
12 \div 2 &= 6 \quad \text{remainder } 0 \\
6 \div 2 &= 3 \quad \text{remainder } 0 \\
3 \div 2 &= 1 \quad \text{remainder } 1 \\
1 \div 2 &= 0 \quad \text{remainder } 1 \quad \text{(most significant bit)} \\
\end{align*}
$$

By reading the remainders from bottom to top, we obtain the binary representation of $784$: $1100010000$.

This technique for converting decimal to binary is referred to as the "division by $2$" algorithm. It is a straightforward and effective method for understanding how decimal numbers can be represented in binary, which is essential for data storage and processing in computers. This example illustrates how a seemingly complex process can be simplified into a series of manageable steps, highlighting a fundamental skill in computer science.
    